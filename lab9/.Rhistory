#| echo: false
set.seed(1234)
#source("_common.R")
knitr::opts_chunk$set(error = TRUE)
#| message: false
library(tidymodels)
library(ISLR)
set.seed(1)
sim_data <- tibble(
x1 = rnorm(40),
x2 = rnorm(40),
y  = factor(rep(c(-1, 1), 20))
) %>%
mutate(x1 = ifelse(y == 1, x1 + 1.5, x1),
x2 = ifelse(y == 1, x2 + 1.5, x2))
ggplot(sim_data, aes(x1, x2, color = y)) +
geom_point()
svm_linear_spec <- svm_poly(degree = 1) %>%
set_mode("classification") %>%
set_engine("kernlab", scaled = FALSE)
svm_linear_fit <- svm_linear_spec %>%
set_args(cost = 10) %>%
fit(y ~ ., data = sim_data)
svm_linear_fit
#| message: false
#| fig-alt: |
#|   Scatter chart of sim_data with x2 on the x-axis and x1 on the
#|   y-axis. A gradient going from red through white to blue,
#|   is overlaid. Blue values occur when both x1 and x2 sum to more
#|   than 2 and red values when x1 and x2 sum to less than 2.
#|   The gradient does not appear to seperate the two classes
#|   which is represented by shapes.
library(kernlab)
svm_linear_fit %>%
extract_fit_engine() %>%
plot()
svm_linear_fit <- svm_linear_spec %>%
set_args(cost = 0.1) %>%
fit(y ~ ., data = sim_data)
svm_linear_fit
#| fig-alt: |
#|   Facetted connected scatter chart. x-axis shows different
#|   values of cost, and the y-axis show the performance metric
#|   value. The facets correspond to the two performance metrics
#|   accuracy and roc_auc. Both charts show a constant value for
#|   all values of cost, expect for once where the accuracy skipes.
svm_linear_wf <- workflow() %>%
add_model(svm_linear_spec %>% set_args(cost = tune())) %>%
add_formula(y ~ .)
set.seed(1234)
sim_data_fold <- vfold_cv(sim_data, strata = y)
param_grid <- grid_regular(cost(), levels = 10)
tune_res <- tune_grid(
svm_linear_wf,
resamples = sim_data_fold,
grid = param_grid
)
autoplot(tune_res)
best_cost <- select_best(tune_res, metric = "accuracy")
svm_linear_final <- finalize_workflow(svm_linear_wf, best_cost)
svm_linear_fit <- svm_linear_final %>% fit(sim_data)
set.seed(2)
sim_data_test <- tibble(
x1 = rnorm(20),
x2 = rnorm(20),
y  = factor(rep(c(-1, 1), 10))
) %>%
mutate(x1 = ifelse(y == 1, x1 + 1.5, x1),
x2 = ifelse(y == 1, x2 + 1.5, x2))
augment(svm_linear_fit, new_data = sim_data_test) %>%
conf_mat(truth = y, estimate = .pred_class)
#| fig-alt: |
#|   Scatter plot of sim_data2. Data is in a oblong shape with
#|   points in the middle having color and both ends having
#|   another color.
set.seed(1)
sim_data2 <- tibble(
x1 = rnorm(200) + rep(c(2, -2, 0), c(100, 50, 50)),
x2 = rnorm(200) + rep(c(2, -2, 0), c(100, 50, 50)),
y  = factor(rep(c(1, 2), c(150, 50)))
)
sim_data2 %>%
ggplot(aes(x1, x2, color = y)) +
geom_point()
svm_rbf_spec <- svm_rbf() %>%
set_mode("classification") %>%
set_engine("kernlab")
svm_rbf_fit <- svm_rbf_spec %>%
fit(y ~ ., data = sim_data2)
#| fig-alt: |
#|   Scatter chart of sim_data with x2 on the x-axis and x1 on the
#|   y-axis. A gradient going from red through white to blue,
#|   is overlaid. The grading is blue in the middle of the data
#|   and red at the edges, with a non-linear seperation between
#|   the colors.
svm_rbf_fit %>%
extract_fit_engine() %>%
plot()
set.seed(2)
sim_data2_test <- tibble(
x1 = rnorm(200) + rep(c(2, -2, 0), c(100, 50, 50)),
x2 = rnorm(200) + rep(c(2, -2, 0), c(100, 50, 50)),
y  = factor(rep(c(1, 2), c(150, 50)))
)
augment(svm_rbf_fit, new_data = sim_data2_test) %>%
conf_mat(truth = y, estimate = .pred_class)
augment(svm_rbf_fit, new_data = sim_data2_test) %>%
roc_curve(truth = y, .pred_1)
#| message: false
#| fig-alt: |
#|   A ROC curve plot. 1-specificity along the x-axis and
#|   sensitivity along the y-axis. A dotted line is drawn
#|   along the diagonal. The line quite closely follows
#|   the upper left side.
augment(svm_rbf_fit, new_data = sim_data2_test) %>%
roc_curve(truth = y, .pred_1) %>%
autoplot()
augment(svm_rbf_fit, new_data = sim_data2_test) %>%
roc_auc(truth = y, .pred_1)
#| warning: false
Khan_train <- bind_cols(
y = factor(Khan$ytrain),
as_tibble(Khan$xtrain)
)
Khan_test <- bind_cols(
y = factor(Khan$ytest),
as_tibble(Khan$xtest)
)
dim(Khan_train)
khan_fit <- svm_linear_spec %>%
set_args(cost = 10) %>%
fit(y ~ ., data = Khan_train)
augment(khan_fit, new_data = Khan_train) %>%
conf_mat(truth = y, estimate = .pred_class)
augment(khan_fit, new_data = Khan_test) %>%
conf_mat(truth = y, estimate = .pred_class)
